{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.datasets.demo import download_demo\n",
    "real_data, metadata = download_demo(\n",
    "    modality='single_table',\n",
    "    dataset_name='fake_hotel_guests')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.lite import SingleTablePreset\n",
    "\n",
    "synthesizer = SingleTablePreset(metadata, name='FAST_ML')\n",
    "synthesizer.fit(data=real_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>guest_email</th>\n",
       "      <th>has_rewards</th>\n",
       "      <th>room_type</th>\n",
       "      <th>amenities_fee</th>\n",
       "      <th>checkin_date</th>\n",
       "      <th>checkout_date</th>\n",
       "      <th>room_rate</th>\n",
       "      <th>billing_address</th>\n",
       "      <th>credit_card_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>michaelsanders@shaw.net</td>\n",
       "      <td>False</td>\n",
       "      <td>BASIC</td>\n",
       "      <td>37.89</td>\n",
       "      <td>27 Dec 2020</td>\n",
       "      <td>29 Dec 2020</td>\n",
       "      <td>131.23</td>\n",
       "      <td>49380 Rivers Street\\nSpencerville, AK 68265</td>\n",
       "      <td>4075084747483975747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>randy49@brown.biz</td>\n",
       "      <td>False</td>\n",
       "      <td>BASIC</td>\n",
       "      <td>24.37</td>\n",
       "      <td>30 Dec 2020</td>\n",
       "      <td>02 Jan 2021</td>\n",
       "      <td>114.43</td>\n",
       "      <td>88394 Boyle Meadows\\nConleyberg, TN 22063</td>\n",
       "      <td>180072822063468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>webermelissa@neal.com</td>\n",
       "      <td>True</td>\n",
       "      <td>DELUXE</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17 Sep 2020</td>\n",
       "      <td>18 Sep 2020</td>\n",
       "      <td>368.33</td>\n",
       "      <td>0323 Lisa Station Apt. 208\\nPort Thomas, LA 82585</td>\n",
       "      <td>38983476971380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gsims@terry.com</td>\n",
       "      <td>False</td>\n",
       "      <td>BASIC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28 Dec 2020</td>\n",
       "      <td>31 Dec 2020</td>\n",
       "      <td>115.61</td>\n",
       "      <td>77 Massachusetts Ave\\nCambridge, MA 02139</td>\n",
       "      <td>4969551998845740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>misty33@smith.biz</td>\n",
       "      <td>False</td>\n",
       "      <td>BASIC</td>\n",
       "      <td>16.45</td>\n",
       "      <td>05 Apr 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122.41</td>\n",
       "      <td>1234 Corporate Drive\\nBoston, MA 02116</td>\n",
       "      <td>3558512986488983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>laurabennett@jones-duncan.net</td>\n",
       "      <td>False</td>\n",
       "      <td>BASIC</td>\n",
       "      <td>8.71</td>\n",
       "      <td>04 Jan 2021</td>\n",
       "      <td>06 Jan 2021</td>\n",
       "      <td>103.25</td>\n",
       "      <td>5678 Office Road\\nSan Francisco, CA 94103</td>\n",
       "      <td>3505516387300030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>johnny71@cook.info</td>\n",
       "      <td>False</td>\n",
       "      <td>BASIC</td>\n",
       "      <td>16.31</td>\n",
       "      <td>24 Aug 2020</td>\n",
       "      <td>26 Aug 2020</td>\n",
       "      <td>115.81</td>\n",
       "      <td>953 White Island\\nChristopherside, TN 91366</td>\n",
       "      <td>2224524502892552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>ygarcia@ballard-lopez.net</td>\n",
       "      <td>False</td>\n",
       "      <td>BASIC</td>\n",
       "      <td>30.59</td>\n",
       "      <td>11 Nov 2020</td>\n",
       "      <td>13 Nov 2020</td>\n",
       "      <td>141.61</td>\n",
       "      <td>5678 Office Road\\nSan Francisco, CA 94103</td>\n",
       "      <td>180096250673548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>thomasdale@hall.com</td>\n",
       "      <td>False</td>\n",
       "      <td>BASIC</td>\n",
       "      <td>1.93</td>\n",
       "      <td>16 Jul 2020</td>\n",
       "      <td>18 Jul 2020</td>\n",
       "      <td>136.92</td>\n",
       "      <td>5678 Office Road\\nSan Francisco, CA 94103</td>\n",
       "      <td>4488223821722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>danieltaylor@harper.com</td>\n",
       "      <td>False</td>\n",
       "      <td>BASIC</td>\n",
       "      <td>3.84</td>\n",
       "      <td>22 Mar 2020</td>\n",
       "      <td>25 Mar 2020</td>\n",
       "      <td>143.52</td>\n",
       "      <td>034 Tran Oval\\nHowardshire, VT 40933</td>\n",
       "      <td>213165812201188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       guest_email  has_rewards room_type  amenities_fee  \\\n",
       "0          michaelsanders@shaw.net        False     BASIC          37.89   \n",
       "1                randy49@brown.biz        False     BASIC          24.37   \n",
       "2            webermelissa@neal.com         True    DELUXE           0.00   \n",
       "3                  gsims@terry.com        False     BASIC            NaN   \n",
       "4                misty33@smith.biz        False     BASIC          16.45   \n",
       "..                             ...          ...       ...            ...   \n",
       "495  laurabennett@jones-duncan.net        False     BASIC           8.71   \n",
       "496             johnny71@cook.info        False     BASIC          16.31   \n",
       "497      ygarcia@ballard-lopez.net        False     BASIC          30.59   \n",
       "498            thomasdale@hall.com        False     BASIC           1.93   \n",
       "499        danieltaylor@harper.com        False     BASIC           3.84   \n",
       "\n",
       "    checkin_date checkout_date  room_rate  \\\n",
       "0    27 Dec 2020   29 Dec 2020     131.23   \n",
       "1    30 Dec 2020   02 Jan 2021     114.43   \n",
       "2    17 Sep 2020   18 Sep 2020     368.33   \n",
       "3    28 Dec 2020   31 Dec 2020     115.61   \n",
       "4    05 Apr 2020           NaN     122.41   \n",
       "..           ...           ...        ...   \n",
       "495  04 Jan 2021   06 Jan 2021     103.25   \n",
       "496  24 Aug 2020   26 Aug 2020     115.81   \n",
       "497  11 Nov 2020   13 Nov 2020     141.61   \n",
       "498  16 Jul 2020   18 Jul 2020     136.92   \n",
       "499  22 Mar 2020   25 Mar 2020     143.52   \n",
       "\n",
       "                                       billing_address   credit_card_number  \n",
       "0          49380 Rivers Street\\nSpencerville, AK 68265  4075084747483975747  \n",
       "1            88394 Boyle Meadows\\nConleyberg, TN 22063      180072822063468  \n",
       "2    0323 Lisa Station Apt. 208\\nPort Thomas, LA 82585       38983476971380  \n",
       "3            77 Massachusetts Ave\\nCambridge, MA 02139     4969551998845740  \n",
       "4               1234 Corporate Drive\\nBoston, MA 02116     3558512986488983  \n",
       "..                                                 ...                  ...  \n",
       "495          5678 Office Road\\nSan Francisco, CA 94103     3505516387300030  \n",
       "496        953 White Island\\nChristopherside, TN 91366     2224524502892552  \n",
       "497          5678 Office Road\\nSan Francisco, CA 94103      180096250673548  \n",
       "498          5678 Office Road\\nSan Francisco, CA 94103        4488223821722  \n",
       "499               034 Tran Oval\\nHowardshire, VT 40933      213165812201188  \n",
       "\n",
       "[500 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from sdv.single_table import CTGANSynthesizer\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sdv.lite import SingleTablePreset\n",
    "\n",
    "# push + prd\n",
    "\n",
    "# imbalanced에 data level로 해결하는 모델\n",
    "class FiGen:\n",
    "    def __init__(self, ratio: float, index: List[str]):\n",
    "        \"\"\"\n",
    "        고정적으로 사용하는 값을 저장\n",
    "        \n",
    "        Args:\n",
    "            ratio (float): small class+생성된 데이터와 large class의 비율 \n",
    "            index (List[int]): 범주형, 연속형 구분하기 위한 연속형 변수의 컬럼명 인덱스       \n",
    "        \"\"\"\n",
    "        self.result = 0\n",
    "        self.ratio = ratio\n",
    "        self.index = index\n",
    "\n",
    "\n",
    "    def extract_middle_percent(self, data: pd.DataFrame, start: float, last:float):\n",
    "        \"\"\"\n",
    "        데이터의 분포 중 중간 부분을 추출 \n",
    "        \n",
    "        Args:\n",
    "            data : 입력 데이터\n",
    "            start : 추출 시작 percentile \n",
    "            last : 추출 끝 percentile\n",
    "        Returns:    \n",
    "            데이터의 분포 중 중간 부분을 추출하여 리턴\n",
    "        \"\"\"\n",
    "        scaler = StandardScaler()\n",
    "        data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "        kde = KernelDensity(kernel=\"gaussian\", bandwidth=0.5).fit(\n",
    "            data_scaled\n",
    "        )  ##TODO: 계산이 안터지도록 하기, gmm으로 변경\n",
    "\n",
    "        log_prob = kde.score_samples(data_scaled)\n",
    "        prob = np.exp(log_prob)\n",
    "        threshold_low, threshold_high = np.percentile(prob, [start, last])\n",
    "        mask = np.logical_and(prob >= threshold_low, prob <= threshold_high)\n",
    "        data_middle = data[mask]\n",
    "\n",
    "        if len(data_middle) > 0:\n",
    "            return data_middle\n",
    "        else:\n",
    "            print(\"No middle 50% found, returning original data\")\n",
    "            return np.array([])\n",
    "\n",
    "    def find_categorical(\n",
    "        self, suitable_generated_small_X: pd.DataFrame, categorical_small_X: pd.DataFrame, small_X: pd.DataFrame\n",
    "    ):  # ****************\n",
    "        \"\"\"\n",
    "        생성된 연속형변수와 기존 연속형 변수의 cosine simmilarity를 기준으로 가장 가까운 기존 변수를 찾은 후 해당 변수의 범주형 값을 가져옴\n",
    "        \n",
    "        Args:\n",
    "            suitable_generated_small_X : 생성된 적합한 small class의 연속형 변수만 있는 x \n",
    "            small_X : small class의 연속형, 범주형 변수가 모두 있는 orgin x\n",
    "        Returns:\n",
    "            생성된 연속 변수를 범주형 변수값이 결합된 형태로 리턴 \n",
    "        \"\"\"\n",
    "\n",
    "        # Min-Max 스케일링을 위한 객체 생성\n",
    "        scaler = MinMaxScaler()\n",
    "\n",
    "        # 열별 Min-Max 스케일링 수행\n",
    "        suitable_generated_small_scaled_X = pd.DataFrame(\n",
    "            scaler.fit_transform(suitable_generated_small_X),\n",
    "            columns=suitable_generated_small_X.columns,\n",
    "        )\n",
    "\n",
    "        orgin_small_non_cat_scaled_X = pd.DataFrame(\n",
    "            scaler.fit_transform(small_X.iloc[:, self.index]),\n",
    "            columns=small_X.iloc[:, self.index].columns,\n",
    "        )\n",
    "\n",
    "        # 데이터프레임을 numpy 배열로 변환\n",
    "        array_mxn = suitable_generated_small_scaled_X.values\n",
    "        array_kxn = orgin_small_non_cat_scaled_X.values\n",
    "\n",
    "        # 행렬곱 수행 (mxn과 nxk로 계산)\n",
    "        result_array = np.dot(array_mxn, array_kxn)\n",
    "\n",
    "        # 각 행에서 최대값을 가지는 열의 인덱스를 가져와서 리스트로 만들기\n",
    "        max_indices = np.argmax(result_array, axis=1).tolist()\n",
    "\n",
    "        # 가장큰 열 인덱스가 들어있는 리스트의 인덱스에 따라 범주형 값 가져오기\n",
    "        synthetic_small_X = pd.concat(\n",
    "            [suitable_generated_small_scaled_X, categorical_small_X.loc[max_indices]],\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "        return synthetic_small_X\n",
    "\n",
    "    def suitable_judge(self, midlle_small_X:pd.DataFrame, small_X: pd.DataFrame, large_X: pd.DataFrame):\n",
    "        \"\"\"\n",
    "           generated_x : 생성된 small class x 데이터\n",
    "           small_X : 원본 small class x 데이터\n",
    "           large_X : 원본 large class x 데이터\n",
    "        \"\"\"\n",
    "\n",
    "        center_small_X = np.mean(\n",
    "            small_X.cpu().numpy(), axis=1, dtype=np.float64, out=None \n",
    "        )\n",
    "\n",
    "        radius_small_X = np.max(\n",
    "            np.linalg.norm(small_X.cpu().numpy() - center_small_X, axis=1)\n",
    "        )\n",
    "\n",
    "        center_large_X = np.mean(\n",
    "            large_X.cpu().numpy(), axis=1, dtype=np.float64, out=None \n",
    "        )\n",
    "\n",
    "        radius_large_X = np.max(\n",
    "            np.linalg.norm(large_X.cpu().numpy() - center_large_X, axis=1)\n",
    "        )\n",
    "\n",
    "        synthetic_sample = pd.DataFrame()  # 최종 합치기\n",
    "        \n",
    "\n",
    "        # ctgan으로 연속형 생성 부분\n",
    "        metadata = SingleTableMetadata()\n",
    "        metadata.detect_from_dataframe(data=midlle_small_X)\n",
    "        \n",
    "        synthesizer = SingleTablePreset(metadata, name='FAST_ML')\n",
    "        synthesizer.fit(data=midlle_small_X)\n",
    "                \n",
    "            \n",
    "        # large class의 데이터 사이즈 만큼 데이터 생성\n",
    "        synthetic_data = synthesizer.sample(num_rows=len(large_X)) # 새로운 데이터를 생성하는 비용 vs 데이터가 적합한지 판단하는 비용 \n",
    "                \n",
    "\n",
    "        # 합성된 개수 / 원래 클래스 개수 <= ratio 만족시 그만 생성하는 것으로\n",
    "        i = 0 \n",
    "        while len(synthetic_sample) / len(large_X) >= self.ratio:\n",
    "            \n",
    "            z = synthetic_data.loc[i]\n",
    "\n",
    "            # 생성된 small class 데이터가 small, large class 중 small에 가까운지, small class의 지름을 넘지는 않는지\n",
    "            if (\n",
    "                np.linalg.norm(z - center_small_X) < np.linalg.norm(z - center_large_X)\n",
    "                and np.linalg.norm(z - center_small_X) < radius_small_X\n",
    "            ):\n",
    "                synthetic_sample.append(z)  \n",
    "                \n",
    "            i+=1\n",
    "            \n",
    "            # 생성된 샘플을 다 검정해도 생성 비율을 만족하지 못할 경우\n",
    "            if i+1 == len(large_X) and len(synthetic_sample) / len(large_X) < self.ratio:\n",
    "                i=0\n",
    "                synthetic_data = synthesizer.sample(num_rows=len(large_X))\n",
    "                \n",
    "        return synthetic_sample.reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    def generate_synthetic(\n",
    "        self, small_X: pd.DataFrame, large_X: pd.DataFrame, small_Y: pd.DataFrame, large_Y: pd.DataFrame\n",
    "    ) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "        \"\"\"\n",
    "        생성된 데이터셋 + 기존 데이터셋을 합쳐 통합 데이터셋을 생성\n",
    "        \n",
    "        Args:\n",
    "            small_X (pd.DataFrame): small class의 x\n",
    "            large_X (pd.DataFrame): large class의 x\n",
    "        Returns:\n",
    "            생성된 데이터셋 + 기존 데이터셋을 합쳐 통합 데이터셋을 리턴\n",
    "        \"\"\"\n",
    "        # 연속형 변수만 가져오는 부분\n",
    "        continue_small_X = small_X.iloc[:, self.index]\n",
    "        continue_large_X = large_X.iloc[:, self.index]\n",
    "\n",
    "        # 범주형 변수만 가져오는 부분\n",
    "        categorical_small_X = small_X.iloc[\n",
    "            :, [i for i in range(len(small_X.columns)) if i not in self.index]\n",
    "        ]\n",
    "        categorical_large_X = large_X.iloc[\n",
    "            :, [i for i in range(len(small_X.columns)) if i not in self.index]\n",
    "        ]\n",
    "\n",
    "        # 상위 n% 필터링 부분\n",
    "        midlle_small_X = self.extract_middle_percent(\n",
    "            continue_small_X, 25, 75\n",
    "        )  ##TODO: 추후에 하이퍼 파라미터로 뺄 수 있음\n",
    "\n",
    "        midlle_large_X = self.extract_middle_percent(\n",
    "            continue_large_X, 15, 85\n",
    "        )  ##TODO: 추후에 하이퍼 파라미터로 뺄 수 있음\n",
    "\n",
    "        # 연속형 데이터 생성 및 데이터 적합 판단\n",
    "\n",
    "        suitable_generated_small_X = self.suitable_judge(midlle_small_X, small_X, large_X)\n",
    "\n",
    "        # 코사인 유사도 기반으로 가장 가까운 기존 변수의 범주형 변수 값 가져오기\n",
    "\n",
    "        synthetic_small_X = self.find_categorical(\n",
    "            suitable_generated_small_X, categorical_small_X, small_X ,self.index\n",
    "        )\n",
    "\n",
    "        # small class와 large class 합치기\n",
    "\n",
    "        origin_small_x = pd.concat(\n",
    "            [midlle_small_X, categorical_small_X.loc[midlle_small_X.index]], axis=1\n",
    "        )\n",
    "\n",
    "        small_total_x = pd.concat([synthetic_small_X, origin_small_x], axis=0)\n",
    "\n",
    "        small_total_x[\"target\"] = small_Y[0]\n",
    "\n",
    "        origin_large_x = pd.concat(\n",
    "            [midlle_large_X, categorical_large_X.loc[midlle_large_X.index]], axis=1\n",
    "        )\n",
    "\n",
    "        origin_large_x[\"target\"] = small_Y[0]\n",
    "        total = pd.concat([small_total_x, origin_large_x], axis=0)\n",
    "        return total.drop(columns=[\"target\"]), total[\"target\"]\n",
    "    \n",
    "    \n",
    "    def fit(\n",
    "        self,\n",
    "        small_X: pd.DataFrame,\n",
    "        small_Y: pd.DataFrame,\n",
    "        large_X: pd.DataFrame,\n",
    "        large_Y: pd.DataFrame,\n",
    "        ratio : float ,\n",
    "        index : list[int]\n",
    "        \n",
    "    ):\n",
    "        \"\"\"\n",
    "        데이터를 학습 시키는 함수\n",
    "        Args:\n",
    "            small_X (pd.DataFrame): small class의 x\n",
    "            small_Y (pd.DataFrame): small class의 y\n",
    "            large_X (pd.DataFrame): large class의 x\n",
    "            large_Y (pd.DataFrame): large class의 y\n",
    "        Returns:\n",
    "            Tuple[pd.DataFrame, pd.DataFrame]: synthetic X, y\n",
    "        \n",
    "        \"\"\"\n",
    "        # 합성+ 기존 data set 생성\n",
    "        synthetic_X, synthetic_Y = self.generate_synthetic(\n",
    "            small_X, large_X,small_Y, large_Y\n",
    "        )\n",
    "        return synthetic_X, synthetic_Y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEN = FiGen(0.3, [2,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'DELUXE'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb 셀 7\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m ratio \u001b[39m=\u001b[39m \u001b[39m0.3\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m index \u001b[39m=\u001b[39m [\u001b[39m2\u001b[39m,\u001b[39m5\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m GEN\u001b[39m.\u001b[39;49mfit(small_X, small_Y, large_X, large_Y, \u001b[39m0.3\u001b[39;49m, [\u001b[39m2\u001b[39;49m,\u001b[39m5\u001b[39;49m])\n",
      "\u001b[1;32m/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb 셀 7\u001b[0m in \u001b[0;36mFiGen.fit\u001b[0;34m(self, small_X, small_Y, large_X, large_Y, ratio, index)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb#W4sZmlsZQ%3D%3D?line=235'>236</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb#W4sZmlsZQ%3D%3D?line=236'>237</a>\u001b[0m \u001b[39m데이터를 학습 시키는 함수\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb#W4sZmlsZQ%3D%3D?line=237'>238</a>\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb#W4sZmlsZQ%3D%3D?line=244'>245</a>\u001b[0m \u001b[39m\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb#W4sZmlsZQ%3D%3D?line=245'>246</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb#W4sZmlsZQ%3D%3D?line=246'>247</a>\u001b[0m \u001b[39m# 합성+ 기존 data set 생성\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb#W4sZmlsZQ%3D%3D?line=247'>248</a>\u001b[0m synthetic_X, synthetic_Y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_synthetic(\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb#W4sZmlsZQ%3D%3D?line=248'>249</a>\u001b[0m     small_X, large_X,small_Y, large_Y\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb#W4sZmlsZQ%3D%3D?line=249'>250</a>\u001b[0m )\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb#W4sZmlsZQ%3D%3D?line=250'>251</a>\u001b[0m \u001b[39mreturn\u001b[39;00m synthetic_X, synthetic_Y\n",
      "\u001b[1;32m/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb 셀 7\u001b[0m in \u001b[0;36mFiGen.generate_synthetic\u001b[0;34m(self, small_X, large_X, small_Y, large_Y)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb#W4sZmlsZQ%3D%3D?line=183'>184</a>\u001b[0m categorical_large_X \u001b[39m=\u001b[39m large_X\u001b[39m.\u001b[39miloc[\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb#W4sZmlsZQ%3D%3D?line=184'>185</a>\u001b[0m     :, [i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(small_X\u001b[39m.\u001b[39mcolumns)) \u001b[39mif\u001b[39;00m i \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex]\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb#W4sZmlsZQ%3D%3D?line=185'>186</a>\u001b[0m ]\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb#W4sZmlsZQ%3D%3D?line=187'>188</a>\u001b[0m \u001b[39m# 상위 n% 필터링 부분\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb#W4sZmlsZQ%3D%3D?line=188'>189</a>\u001b[0m midlle_small_X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mextract_middle_percent(\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb#W4sZmlsZQ%3D%3D?line=189'>190</a>\u001b[0m     continue_small_X, \u001b[39m25\u001b[39;49m, \u001b[39m75\u001b[39;49m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb#W4sZmlsZQ%3D%3D?line=190'>191</a>\u001b[0m )  \u001b[39m##TODO: 추후에 하이퍼 파라미터로 뺄 수 있음\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb#W4sZmlsZQ%3D%3D?line=192'>193</a>\u001b[0m midlle_large_X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextract_middle_percent(\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb#W4sZmlsZQ%3D%3D?line=193'>194</a>\u001b[0m     continue_large_X, \u001b[39m15\u001b[39m, \u001b[39m85\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb#W4sZmlsZQ%3D%3D?line=194'>195</a>\u001b[0m )  \u001b[39m##TODO: 추후에 하이퍼 파라미터로 뺄 수 있음\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb#W4sZmlsZQ%3D%3D?line=196'>197</a>\u001b[0m \u001b[39m# 연속형 데이터 생성 및 데이터 적합 판단\u001b[39;00m\n",
      "\u001b[1;32m/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb 셀 7\u001b[0m in \u001b[0;36mFiGen.extract_middle_percent\u001b[0;34m(self, data, start, last)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb#W4sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb#W4sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m데이터의 분포 중 중간 부분을 추출 \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb#W4sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb#W4sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m    데이터의 분포 중 중간 부분을 추출하여 리턴\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb#W4sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb#W4sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m scaler \u001b[39m=\u001b[39m StandardScaler()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb#W4sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m data_scaled \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39;49mfit_transform(data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb#W4sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m kde \u001b[39m=\u001b[39m KernelDensity(kernel\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgaussian\u001b[39m\u001b[39m\"\u001b[39m, bandwidth\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m)\u001b[39m.\u001b[39mfit(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb#W4sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     data_scaled\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb#W4sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m )  \u001b[39m##TODO: 계산이 안터지도록 하기, gmm으로 변경\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jangsehwan/Financial-Imbalanced-Data-With-Deep-Density-Hybrid-Sampling/scripts/f_ddhs_v0.01.06.ipynb#W4sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m log_prob \u001b[39m=\u001b[39m kde\u001b[39m.\u001b[39mscore_samples(data_scaled)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:852\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    849\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    850\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    851\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 852\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    853\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    854\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    855\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:806\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[39m# Reset internal state before fitting\u001b[39;00m\n\u001b[1;32m    805\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> 806\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpartial_fit(X, y, sample_weight)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:841\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[39m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[1;32m    810\u001b[0m \n\u001b[1;32m    811\u001b[0m \u001b[39mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[39m    Fitted scaler.\u001b[39;00m\n\u001b[1;32m    839\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    840\u001b[0m first_call \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mn_samples_seen_\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 841\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    842\u001b[0m     X,\n\u001b[1;32m    843\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    844\u001b[0m     estimator\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    845\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[1;32m    846\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    847\u001b[0m     reset\u001b[39m=\u001b[39;49mfirst_call,\n\u001b[1;32m    848\u001b[0m )\n\u001b[1;32m    849\u001b[0m n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m    851\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:566\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    565\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 566\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    567\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    568\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:746\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    744\u001b[0m         array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mastype(dtype, casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    745\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 746\u001b[0m         array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    747\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[1;32m    748\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    749\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    750\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:2064\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2063\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m-> 2064\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'DELUXE'"
     ]
    }
   ],
   "source": [
    "# y = has_rewards\n",
    "small_X = real_data[real_data['has_rewards'] == True]\n",
    "small_Y = real_data[real_data['has_rewards'] == True].iloc[:, [1]]\n",
    "large_X = real_data[real_data['has_rewards'] == False]\n",
    "large_Y = real_data[real_data['has_rewards'] == False].iloc[:, [1]]\n",
    "ratio = 0.3\n",
    "index = [2,5]\n",
    "GEN.fit(small_X, small_Y, large_X, large_Y, 0.3, [2,5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>guest_email</th>\n",
       "      <th>has_rewards</th>\n",
       "      <th>amenities_fee</th>\n",
       "      <th>checkin_date</th>\n",
       "      <th>room_rate</th>\n",
       "      <th>billing_address</th>\n",
       "      <th>credit_card_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>michaelsanders@shaw.net</td>\n",
       "      <td>False</td>\n",
       "      <td>37.89</td>\n",
       "      <td>27 Dec 2020</td>\n",
       "      <td>131.23</td>\n",
       "      <td>49380 Rivers Street\\nSpencerville, AK 68265</td>\n",
       "      <td>4075084747483975747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>randy49@brown.biz</td>\n",
       "      <td>False</td>\n",
       "      <td>24.37</td>\n",
       "      <td>30 Dec 2020</td>\n",
       "      <td>114.43</td>\n",
       "      <td>88394 Boyle Meadows\\nConleyberg, TN 22063</td>\n",
       "      <td>180072822063468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gsims@terry.com</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28 Dec 2020</td>\n",
       "      <td>115.61</td>\n",
       "      <td>77 Massachusetts Ave\\nCambridge, MA 02139</td>\n",
       "      <td>4969551998845740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>misty33@smith.biz</td>\n",
       "      <td>False</td>\n",
       "      <td>16.45</td>\n",
       "      <td>05 Apr 2020</td>\n",
       "      <td>122.41</td>\n",
       "      <td>1234 Corporate Drive\\nBoston, MA 02116</td>\n",
       "      <td>3558512986488983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>phillipsmatthew@powers-martinez.com</td>\n",
       "      <td>False</td>\n",
       "      <td>19.56</td>\n",
       "      <td>22 Nov 2020</td>\n",
       "      <td>108.09</td>\n",
       "      <td>923 Bonilla Extension Apt. 787\\nBrianside, TN ...</td>\n",
       "      <td>6011956907055260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>laurabennett@jones-duncan.net</td>\n",
       "      <td>False</td>\n",
       "      <td>8.71</td>\n",
       "      <td>04 Jan 2021</td>\n",
       "      <td>103.25</td>\n",
       "      <td>5678 Office Road\\nSan Francisco, CA 94103</td>\n",
       "      <td>3505516387300030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>johnny71@cook.info</td>\n",
       "      <td>False</td>\n",
       "      <td>16.31</td>\n",
       "      <td>24 Aug 2020</td>\n",
       "      <td>115.81</td>\n",
       "      <td>953 White Island\\nChristopherside, TN 91366</td>\n",
       "      <td>2224524502892552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>ygarcia@ballard-lopez.net</td>\n",
       "      <td>False</td>\n",
       "      <td>30.59</td>\n",
       "      <td>11 Nov 2020</td>\n",
       "      <td>141.61</td>\n",
       "      <td>5678 Office Road\\nSan Francisco, CA 94103</td>\n",
       "      <td>180096250673548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>thomasdale@hall.com</td>\n",
       "      <td>False</td>\n",
       "      <td>1.93</td>\n",
       "      <td>16 Jul 2020</td>\n",
       "      <td>136.92</td>\n",
       "      <td>5678 Office Road\\nSan Francisco, CA 94103</td>\n",
       "      <td>4488223821722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>danieltaylor@harper.com</td>\n",
       "      <td>False</td>\n",
       "      <td>3.84</td>\n",
       "      <td>22 Mar 2020</td>\n",
       "      <td>143.52</td>\n",
       "      <td>034 Tran Oval\\nHowardshire, VT 40933</td>\n",
       "      <td>213165812201188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>447 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             guest_email  has_rewards  amenities_fee  \\\n",
       "0                michaelsanders@shaw.net        False          37.89   \n",
       "1                      randy49@brown.biz        False          24.37   \n",
       "3                        gsims@terry.com        False            NaN   \n",
       "4                      misty33@smith.biz        False          16.45   \n",
       "6    phillipsmatthew@powers-martinez.com        False          19.56   \n",
       "..                                   ...          ...            ...   \n",
       "495        laurabennett@jones-duncan.net        False           8.71   \n",
       "496                   johnny71@cook.info        False          16.31   \n",
       "497            ygarcia@ballard-lopez.net        False          30.59   \n",
       "498                  thomasdale@hall.com        False           1.93   \n",
       "499              danieltaylor@harper.com        False           3.84   \n",
       "\n",
       "    checkin_date  room_rate  \\\n",
       "0    27 Dec 2020     131.23   \n",
       "1    30 Dec 2020     114.43   \n",
       "3    28 Dec 2020     115.61   \n",
       "4    05 Apr 2020     122.41   \n",
       "6    22 Nov 2020     108.09   \n",
       "..           ...        ...   \n",
       "495  04 Jan 2021     103.25   \n",
       "496  24 Aug 2020     115.81   \n",
       "497  11 Nov 2020     141.61   \n",
       "498  16 Jul 2020     136.92   \n",
       "499  22 Mar 2020     143.52   \n",
       "\n",
       "                                       billing_address   credit_card_number  \n",
       "0          49380 Rivers Street\\nSpencerville, AK 68265  4075084747483975747  \n",
       "1            88394 Boyle Meadows\\nConleyberg, TN 22063      180072822063468  \n",
       "3            77 Massachusetts Ave\\nCambridge, MA 02139     4969551998845740  \n",
       "4               1234 Corporate Drive\\nBoston, MA 02116     3558512986488983  \n",
       "6    923 Bonilla Extension Apt. 787\\nBrianside, TN ...     6011956907055260  \n",
       "..                                                 ...                  ...  \n",
       "495          5678 Office Road\\nSan Francisco, CA 94103     3505516387300030  \n",
       "496        953 White Island\\nChristopherside, TN 91366     2224524502892552  \n",
       "497          5678 Office Road\\nSan Francisco, CA 94103      180096250673548  \n",
       "498          5678 Office Road\\nSan Francisco, CA 94103        4488223821722  \n",
       "499               034 Tran Oval\\nHowardshire, VT 40933      213165812201188  \n",
       "\n",
       "[447 rows x 7 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_X.iloc[:, [i for i in range(len(small_X.columns)) if i not in index] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
