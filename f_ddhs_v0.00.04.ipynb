{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "933c78e8",
   "metadata": {},
   "source": [
    "1. 연속형, 범주형 판단\n",
    "2. small, big class에 따라 분리\n",
    "3. 각 class에 따로 연속형만 GMM(k=2) fitting 후 상위 N % 만 Filtering\n",
    "4. ctgan으로 연속형 변수만 생성 후 Density 기반의 적합성 판단\n",
    "5. 생성된 연속형 변수와 cosine similarity 기반의 가장 가까운 기존 변수의 범주형값 카피"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "704d72ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ctgan in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (0.7.3)\n",
      "Requirement already satisfied: packaging<22,>=20 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from ctgan) (21.3)\n",
      "Requirement already satisfied: rdt<2.0,>=1.3.0 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from ctgan) (1.6.0)\n",
      "Requirement already satisfied: numpy<2,>=1.20.0 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from ctgan) (1.21.5)\n",
      "Requirement already satisfied: pandas>=1.1.3 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from ctgan) (1.4.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from ctgan) (1.13.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from packaging<22,>=20->ctgan) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.1.3->ctgan) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.1.3->ctgan) (2022.1)\n",
      "Requirement already satisfied: psutil<6,>=5.7 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from rdt<2.0,>=1.3.0->ctgan) (5.8.0)\n",
      "Requirement already satisfied: Faker>=10 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from rdt<2.0,>=1.3.0->ctgan) (14.2.1)\n",
      "Requirement already satisfied: scipy<2,>=1.5.4 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from rdt<2.0,>=1.3.0->ctgan) (1.7.3)\n",
      "Requirement already satisfied: scikit-learn<2,>=0.24 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from rdt<2.0,>=1.3.0->ctgan) (1.0.2)\n",
      "Requirement already satisfied: typing-extensions in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ctgan) (4.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=1.1.3->ctgan) (1.16.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn<2,>=0.24->rdt<2.0,>=1.3.0->ctgan) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn<2,>=0.24->rdt<2.0,>=1.3.0->ctgan) (2.2.0)\n",
      "Requirement already satisfied: sdv in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (1.2.1)\n",
      "Requirement already satisfied: Faker<15,>=10 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from sdv) (14.2.1)\n",
      "Requirement already satisfied: graphviz<1,>=0.13.2 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from sdv) (0.20.1)\n",
      "Requirement already satisfied: tqdm<5,>=4.15 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from sdv) (4.64.0)\n",
      "Requirement already satisfied: copulas<0.10,>=0.9.0 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from sdv) (0.9.0)\n",
      "Requirement already satisfied: ctgan<0.8,>=0.7.2 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from sdv) (0.7.3)\n",
      "Requirement already satisfied: deepecho<0.5,>=0.4.1 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from sdv) (0.4.1)\n",
      "Requirement already satisfied: rdt<2,>=1.5.0 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from sdv) (1.6.0)\n",
      "Requirement already satisfied: sdmetrics<0.11,>=0.10.0 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from sdv) (0.10.1)\n",
      "Requirement already satisfied: cloudpickle<3.0,>=2.1.0 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from sdv) (2.2.1)\n",
      "Requirement already satisfied: boto3<2,>=1.15.0 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from sdv) (1.24.2)\n",
      "Requirement already satisfied: botocore<2,>=1.18 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from sdv) (1.27.2)\n",
      "Requirement already satisfied: numpy<1.25.0,>=1.20.0 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from sdv) (1.21.5)\n",
      "Requirement already satisfied: pandas>=1.1.3 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from sdv) (1.4.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from boto3<2,>=1.15.0->sdv) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from boto3<2,>=1.15.0->sdv) (0.6.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from botocore<2,>=1.18->sdv) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from botocore<2,>=1.18->sdv) (1.26.9)\n",
      "Requirement already satisfied: scipy<2,>=1.5.4 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from copulas<0.10,>=0.9.0->sdv) (1.7.3)\n",
      "Requirement already satisfied: matplotlib<4,>=3.4.0 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from copulas<0.10,>=0.9.0->sdv) (3.5.2)\n",
      "Requirement already satisfied: packaging<22,>=20 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from ctgan<0.8,>=0.7.2->sdv) (21.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from ctgan<0.8,>=0.7.2->sdv) (1.13.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.1.3->sdv) (2022.1)\n",
      "Requirement already satisfied: psutil<6,>=5.7 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from rdt<2,>=1.5.0->sdv) (5.8.0)\n",
      "Requirement already satisfied: scikit-learn<2,>=0.24 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from rdt<2,>=1.5.0->sdv) (1.0.2)\n",
      "Requirement already satisfied: plotly<6,>=5.10.0 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from sdmetrics<0.11,>=0.10.0->sdv) (5.15.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from matplotlib<4,>=3.4.0->copulas<0.10,>=0.9.0->sdv) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from matplotlib<4,>=3.4.0->copulas<0.10,>=0.9.0->sdv) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from matplotlib<4,>=3.4.0->copulas<0.10,>=0.9.0->sdv) (1.4.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from matplotlib<4,>=3.4.0->copulas<0.10,>=0.9.0->sdv) (9.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from matplotlib<4,>=3.4.0->copulas<0.10,>=0.9.0->sdv) (3.0.4)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from plotly<6,>=5.10.0->sdmetrics<0.11,>=0.10.0->sdv) (8.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<2,>=1.18->sdv) (1.16.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn<2,>=0.24->rdt<2,>=1.5.0->sdv) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn<2,>=0.24->rdt<2,>=1.5.0->sdv) (2.2.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ctgan<0.8,>=0.7.2->sdv) (4.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install ctgan\n",
    "!pip install sdv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bd4be1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.single_table import CTGANSynthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e17c5823",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.datasets.demo import download_demo\n",
    "\n",
    "data, metadata = download_demo(\n",
    "    modality='single_table',\n",
    "    dataset_name='fake_hotel_guests'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f6f92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n",
      "/Users/jangsehwan/opt/anaconda3/lib/python3.9/site-packages/rdt/transformers/base.py:132: FutureWarning: Future versions of RDT will not support the 'model_missing_values' parameter. Please switch to using the 'missing_value_generation' parameter to select your strategy.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "synthesizer = CTGANSynthesizer(metadata)\n",
    "synthesizer.fit(data)\n",
    "\n",
    "synthetic_data = synthesizer.sample(num_rows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1054ea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f89dd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GMM: n_components = 모델의 총 수\n",
    "gmm = GaussianMixture(n_components=3, random_state=0)\n",
    "gmm.fit(iris.data)\n",
    "gmm_cluster_labels = gmm.predict(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b32945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b3da0f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sdv.tabular'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msdv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtabular\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CTGAN\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msdv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m evaluate\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneighbors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KernelDensity\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sdv.tabular'"
     ]
    }
   ],
   "source": [
    "from sdv.tabular import CTGAN\n",
    "from sdv.evaluation import evaluate\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "batch_size = 5000\n",
    "epochs = 100\n",
    "model = CTGAN(batch_size=batch_size, epochs=epochs, verbose=True)\n",
    "model.fit(train_df)\n",
    "model.save('ctgan_30daysofml_model.pkl')\n",
    "\n",
    "n_generated_data = 1000\n",
    "generated_df = model.sample(n_generated_data)\n",
    "\n",
    "score = evaluate(generated_df, train_df.sample(n_generated_data))\n",
    "score\n",
    "\n",
    "# ctgan\n",
    "class Autoencoder(nn.Module):\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "# imbalanced에 data level로 해결하는 모델\n",
    "class DDHS:\n",
    "    \n",
    "  #데이터를 KDE로 가우시안 분포를 이용하여 중간 %를 추출하는 함수\n",
    "  # start, last에 퍼센트를 입력\n",
    "\n",
    "  def extract_middle_percent(self,data, start, last):\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "    kde = KernelDensity(kernel='gaussian', bandwidth=0.5).fit(data_scaled)\n",
    "    \n",
    "    log_prob = kde.score_samples(data_scaled)\n",
    "    prob = np.exp(log_prob)\n",
    "    threshold_low, threshold_high = np.percentile(prob, [start, last])\n",
    "    mask = np.logical_and(prob >= threshold_low, prob <= threshold_high) #######\n",
    "    data_middle = data[mask]\n",
    "\n",
    "    if len(data_middle) > 0 :\n",
    "      return data_middle\n",
    "    else:  \n",
    "      print(\"No middle 50% found, returning original data\")\n",
    "      return np.array([])\n",
    "\n",
    "  #  각 feature 안의 값을 복원추출하는 함수\n",
    "\n",
    "  def reconstruct_features(self,data):\n",
    "    mean = data.mean(axis=0)\n",
    "    std = data.std(axis=0)\n",
    "    reconstructed = np.random.randn(*data.shape) * std + mean\n",
    "    return reconstructed\n",
    "\n",
    "  # synthetic sample을 생성하는 함수\n",
    "  # 라벨과과 데이터를 하나의 데이터프레임으로 출력\n",
    "  # small class / large class의 비율 = ratio \n",
    "\n",
    "\n",
    "  # 디폴트트 파라미터는 뒤로 빼서 입력하기\n",
    "  def generate_synthetic_sample(self,X,Y, ratio=0.3):\n",
    "\n",
    "    data = pd.concat([X,Y],axis=1)\n",
    "\n",
    "    # small class\n",
    "    data_A = data[data[Y.columns[0]]== Y.value_counts().idxmin()[0]  ].loc[:, data.columns != Y.columns[0]].astype(float).values\n",
    "\n",
    "    # large class \n",
    "    data_B = data[data[Y.columns[0]]== Y.value_counts().idxmax()[0] ].loc[:, data.columns != Y.columns[0]].astype(float).values\n",
    "\n",
    "    # autoencoder를 사용하여 잠재 변수를 추출\n",
    "    with torch.no_grad():\n",
    "        encoded_A, _ = self.model(torch.tensor(data_A).float())\n",
    "        encoded_B, _ = self.model(torch.tensor(data_B).float())\n",
    "  \n",
    "    # Majority : 입력받은 퍼센트 보다 Density가 큰 샘플을 Keep→ 입력받은 퍼센트 샘플을 Classifier 의 Train 데이터로 활용\n",
    "    # Minority : 입력받은 퍼센트 을 사용해서 더 높은 기준을 설정 → 입력받은 퍼센트 샘플을 Classifier 의 Train 데이터로 활용 → 25% 샘플을 Subsequence 생성 과정의 샘플로 활용\n",
    "  \n",
    "    encoded_A_middle = self.extract_middle_percent(encoded_A.cpu().numpy(),50 - self.small_percent/2 , 50+ self.small_percent/2) \n",
    "    encoded_B_middle = self.extract_middle_percent(encoded_B.cpu().numpy(),50 -self.large_percent/2, 50 + self.large_percent/2)\n",
    "\n",
    "    # 중간 25%의 잠재 변수로부터 feature를 복원추출 \n",
    "    reconstructed_features = self.reconstruct_features(self.extract_middle_percent(encoded_A.cpu().numpy(),37.5, 62.5))\n",
    "    # 임의의 위치에 synthetic sample 생성\n",
    "    center_A = np.mean(encoded_A.cpu().numpy(), axis=0, dtype=np.float64, out=None)\n",
    "\n",
    "    center_B = np.mean(encoded_B.numpy(), axis=0, dtype=np.float64, out=None) \n",
    "\n",
    "    radius_A = np.max(np.linalg.norm(encoded_A.cpu().numpy() - center_A, axis=1))\n",
    "\n",
    "    synthetic_sample = pd.DataFrame() # 최종 합치기\n",
    "   \n",
    "   # 합성된 개수 / 원래 클래스 개수\n",
    "    while len(synthetic_sample)/len(data_A) >= ratio :\n",
    "        z = np.random.randn(latent_dim)\n",
    "        if np.linalg.norm(z - center_A) < np.linalg.norm(z - center_B) and np.linalg.norm(z - center_A) < radius_A:\n",
    "            synthetic_sample.append(z) #, ignore_index=True)\n",
    "\n",
    "    # 최종 출력할 데이터 \n",
    "    encoded_B_middle = pd.DataFrame(encoded_B_middle)\n",
    "    encoded_B_middle['label'] = Y.value_counts().idxmin()[0]\n",
    "\n",
    "    encoded_A_middle = pd.DataFrame(encoded_A_middle)\n",
    "    encoded_A_middle['label'] = Y.value_counts().idxmax()[0] \n",
    "\n",
    "    synthetic_sample['label'] = Y.value_counts().idxmax()[0] \n",
    "\n",
    "    ouput = pd.concat([encoded_B_middle,encoded_A_middle,synthetic_sample ] )\n",
    "\n",
    "    x_ = ouput.loc[:, ouput.columns != 'label']\n",
    "    x_.columns = X.columns\n",
    "    y_ = ouput['label']\n",
    "    y_.columns = Y.columns\n",
    "\n",
    "    return x_ , y_\n",
    "\n",
    "  def fit(self,X,Y,large_percent = 50 , small_percent = 75 ,lr = 1e-3 ,num_epochs = 50, ratio = 1):\n",
    "    self.large_percent = large_percent\n",
    "    self.small_percent = small_percent\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    input_dim = len(X.columns) # 데이터의 차원\n",
    "    latent_dim = len(X.columns) # 잠재 변수의 차원\n",
    "    #ratio =  합성된 데이터 수/small class  비율\n",
    "    #large_percent : large class의 추출 비율\n",
    "    #small_percent : small class의 추출 비율 \n",
    "    #lr = 1e-3 # 학습률\n",
    "    #num_epochs = 50 # 학습 에폭 수\n",
    "    \n",
    "    self.model = Autoencoder(input_dim, latent_dim).to(device)\n",
    "    optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "      x = torch.tensor(X.to_numpy()).float()#.to(device)\n",
    "      y = torch.tensor(Y[Y.columns[0]].to_numpy()).float().to(device)\n",
    "\n",
    "      encoded, decoded = self.model(x)\n",
    "      reconstruction_loss = F.mse_loss(decoded, x)\n",
    "      center_loss = self.model.get_center_loss(encoded, y)\n",
    "\n",
    "      loss = reconstruction_loss + center_loss\n",
    "      cross_entropy_loss = F.cross_entropy(decoded, y.long()) # y를 long 형으로 요구\n",
    "      loss += cross_entropy_loss\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "    \n",
    "    synthetic_X, synthetic_Y = self.generate_synthetic_sample(X,Y, ratio)\n",
    "    return synthetic_X, synthetic_Y\n",
    "\n",
    "\n",
    "  def __init__(self):\n",
    "    self.result = 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b47458b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333b1a16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d533d05e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b3d517c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jangsehwan\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8be68aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "magic = pd.read_csv('/Users/jangsehwan/Documents/DDHS개발/magic04.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a7557e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>16.0021</th>\n",
       "      <th>0.1982</th>\n",
       "      <th>22.011</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.7235</td>\n",
       "      <td>0.3773</td>\n",
       "      <td>23.8238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>136.0310</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>-64.8580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.5728</td>\n",
       "      <td>0.3922</td>\n",
       "      <td>-6.4633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.9205</td>\n",
       "      <td>0.1832</td>\n",
       "      <td>28.5525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.1502</td>\n",
       "      <td>0.1340</td>\n",
       "      <td>43.1887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19014</th>\n",
       "      <td>10.9170</td>\n",
       "      <td>0.3934</td>\n",
       "      <td>11.5245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19015</th>\n",
       "      <td>6.7020</td>\n",
       "      <td>0.2784</td>\n",
       "      <td>13.1853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19016</th>\n",
       "      <td>47.5305</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>41.0562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19017</th>\n",
       "      <td>76.9018</td>\n",
       "      <td>0.0683</td>\n",
       "      <td>-93.5224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19018</th>\n",
       "      <td>53.0014</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>-168.4558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19019 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        16.0021  0.1982    22.011\n",
       "0       11.7235  0.3773   23.8238\n",
       "1      136.0310  0.0187  -64.8580\n",
       "2        9.5728  0.3922   -6.4633\n",
       "3       30.9205  0.1832   28.5525\n",
       "4       21.1502  0.1340   43.1887\n",
       "...         ...     ...       ...\n",
       "19014   10.9170  0.3934   11.5245\n",
       "19015    6.7020  0.2784   13.1853\n",
       "19016   47.5305  0.0549   41.0562\n",
       "19017   76.9018  0.0683  -93.5224\n",
       "19018   53.0014  0.1539 -168.4558\n",
       "\n",
       "[19019 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "magic.iloc[:, [1,4,6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b83efe3",
   "metadata": {},
   "source": [
    "# <to do list>\n",
    "\n",
    "1. 순차적으로 구조 점검 및 구현 -> 인덱스로 연속형, 범주형 합치는 부분, 각 함수에서 다음으로 넘어가는 부분  \n",
    "\n",
    "2. 범주형 변수 찾아내는 부분 추가 \n",
    "\n",
    "3. ctgan, gmm 버전 오류해결 : 기존 패키지들 회사버전 확인-> 맞추기\n",
    "\n",
    "4. 코드스타일 통일 \n",
    "\n",
    "\n",
    "    함수, 변수, 속성 => 소문자 + 언더바 조합\n",
    "\n",
    "    ex) lower_underscore\n",
    "\n",
    "    보호해야하는 인스턴스 속성 => 언더바로 시작하자\n",
    "\n",
    "    ex) _lower_start\n",
    "\n",
    "    private 인스턴스 속성 => 더블 언더바로 시작하자\n",
    "\n",
    "    ex) __double_underscore\n",
    "\n",
    "    class, exception => 첫 문자는 대문자 + 파스칼 표기법\n",
    "\n",
    "    파스칼 표기법 : 언더바 없이 모든 문자를 이어서 표현하되, 대문자로 단어를 구분하는 표기법\n",
    "\n",
    "    ex) HelloWorld\n",
    "\n",
    "    상수 => 모든 글자를 대문자로 + 언더바 조합\n",
    "\n",
    "    ex) CAR_VECTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca834f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.single_table import CTGANSynthesizer\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "# imbalanced에 data level로 해결하는 모델\n",
    "class FiGen:\n",
    "    def fit(self,small_X,small_Y,large_X,large_Y,ratio,index):\n",
    "        '''\n",
    "            index : 범주형, 연속형 구분 인덱스\n",
    "            small_X : small class의 x\n",
    "            small_Y : small class의 y\n",
    "            large_X : large class의 x\n",
    "            large_Y : large class의 y\n",
    "            ratio : small class+생성된 데이터와 large class의 비율 \n",
    "            \n",
    "            \n",
    "        '''\n",
    "        self.index = index\n",
    "        self.ratio = ratio\n",
    "        self.index = index \n",
    "    \n",
    "        # 합성+ 기존 data set 생성 \n",
    "        synthetic_X, synthetic_Y = self.generate_synthetic(small_X,large_Y,self.ratio, self.index)\n",
    "        \n",
    "        \n",
    "        return synthetic_X, synthetic_Y\n",
    "    \n",
    "    \n",
    "    def generate_synthetic(self, small_X, large_X, ratio, index ):\n",
    "        '''\n",
    "            small_X : \n",
    "            large_X : \n",
    "            ratio : small class와 large class 의 비율 \n",
    "            index : 연속형 변수의 컬럼 인덱스\n",
    "        '''\n",
    "        \n",
    "        # 연속형 변수만 가져오는 부분 \n",
    "        continue_small_X = small_X.iloc[:,self.index]\n",
    "        continue_large_X = large_X.iloc[:,self.index]\n",
    "        \n",
    "        \n",
    "        # 상위 n% 필터링 부분 \n",
    "        midlle_small_X = extract_middle_percent(self,continue_small_X, 25, 75) # 추후에 하이퍼 파라미터로 뺄 수 있음\n",
    "        \n",
    "        midlle_large_X = extract_middle_percent(self,continue_large_X, 15, 85) # 추후에 하이퍼 파라미터로 뺄 수 있음\n",
    "                \n",
    "        \n",
    "        # ctgan으로 연속형 생성 부분 \n",
    "        \n",
    "        synthesizer.fit(midlle_small_X)\n",
    "        \n",
    "        synthetic_data = synthesizer.sample(num_rows=10) \n",
    "        \n",
    "        # 데이터 적합 판단 \n",
    "        \n",
    "        suitable_generated_small_X = suitable_judge(synthetic_data)\n",
    "        \n",
    "        # 코사인 유사도 기반으로 가장 가까운 기존 변수의 범주형 변수 값 가져오기\n",
    "        \n",
    "        synthetic_small_X = find_categorical(suitable_generated_small_X)\n",
    "        \n",
    "        \n",
    "        # small class와 large class 합치기\n",
    "        \n",
    "        return synthetic_X, synthetic_Y\n",
    "        \n",
    "\n",
    "    def extract_middle_percent(self,data, start, last):\n",
    "        '''\n",
    "            data : 입력 데이터\n",
    "            start : 추출 시작 percentile \n",
    "            last : 추출 끝 percentile\n",
    "        \n",
    "            \n",
    "        '''\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        data_scaled = scaler.fit_transform(data)\n",
    "        \n",
    "        kde = KernelDensity(kernel='gaussian', bandwidth=0.5).fit(data_scaled) # 계산이 안터지도록 하기, gmm으로 변경 \n",
    "    \n",
    "        log_prob = kde.score_samples(data_scaled)\n",
    "        prob = np.exp(log_prob)\n",
    "        threshold_low, threshold_high = np.percentile(prob, [start, last])\n",
    "        mask = np.logical_and(prob >= threshold_low, prob <= threshold_high) \n",
    "        data_middle = data[mask]\n",
    "\n",
    "        if len(data_middle) > 0 :\n",
    "            return data_middle\n",
    "        else:  \n",
    "            print(\"No middle 50% found, returning original data\")\n",
    "            return np.array([])\n",
    "\n",
    "        \n",
    "        \n",
    "    def find_categorical():\n",
    "        '''\n",
    "        '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def suitable_judge(generated_x, small_X, large_X):\n",
    "        '''\n",
    "           generated_x : 생성된 small class x 데이터\n",
    "           small_X : 원본 small class x 데이터\n",
    "           large_X : 원본 large class x 데이터\n",
    "        '''\n",
    "        \n",
    "        center_small_X = np.mean(small_X.cpu().numpy(), axis=0, dtype=np.float64, out=None)\n",
    "        \n",
    "        radius_small_X = np.max(np.linalg.norm(small_X.cpu().numpy() - center_small_X, axis=1))\n",
    "        \n",
    "        center_large_X = np.mean(large_X.cpu().numpy(), axis=0, dtype=np.float64, out=None)\n",
    "        \n",
    "        radius_large_X = np.max(np.linalg.norm(large_X.cpu().numpy() - center_large_X, axis=1))\n",
    "\n",
    "        synthetic_sample = pd.DataFrame() # 최종 합치기\n",
    "        \n",
    "        # 합성된 개수 / 원래 클래스 개수 <= ratio\n",
    "        while len(synthetic_sample)/len(large_X) >= ratio :\n",
    "            \n",
    "            z = generated_x # 얼마나 생성하는 부분 추가, 조건문으로 생성을 N개 후 len(synthetic_sample)/len(large_X) >= ratio 만족시 그만 생성하는 것으로\n",
    "            \n",
    "            # 생성된 small class 데이터가 small, large class 중 small에 가까운지, small class의 지름을 넘지는 않는지\n",
    "            if np.linalg.norm(z - center_small_X) < np.linalg.norm(z - center_large_X ) and np.linalg.norm(z - center_small_X) < radius_small_X:\n",
    "                synthetic_sample.append(z) #, ignore_index=True)\n",
    "                \n",
    "        return synthetic_sample\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.result = 0\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083ef7b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
